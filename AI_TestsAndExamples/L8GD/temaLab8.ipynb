{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.53700017929077, 7.52199983596802, 7.50400018692017, 7.49399995803833, 7.4689998626709, 7.3769998550415, 7.31599998474121, 7.31400012969971, 7.28399991989136, 7.28399991989136, 7.21299982070923, 7.0789999961853, 7.00600004196167, 6.99300003051758, 6.97700023651123, 6.95100021362305, 6.89099979400635, 6.86299991607666, 6.71400022506714, 6.65199995040894, 6.64799976348877, 6.63500022888184, 6.60900020599365, 6.59899997711182, 6.57800006866455, 6.57200002670288, 6.52699995040894, 6.4539999961853, 6.4539999961853, 6.4520001411438, 6.44199991226196, 6.42399978637695, 6.42199993133545, 6.40299987792969, 6.375, 6.35699987411499, 6.3439998626709, 6.16800022125244, 6.10500001907349, 6.09800004959106, 6.08699989318848, 6.08400011062622, 6.07100009918213, 6.00799989700317, 6.00299978256226, 5.97300004959106, 5.97100019454956, 5.96400022506714, 5.96299982070923, 5.95599985122681, 5.92000007629395, 5.90199995040894, 5.87200021743774, 5.84999990463257, 5.83799982070923, 5.83799982070923, 5.82499980926514, 5.82299995422363, 5.82200002670288, 5.81899976730347, 5.80999994277954, 5.75799989700317, 5.71500015258789, 5.62900018692017, 5.62099981307983, 5.61100006103516, 5.56899976730347, 5.52500009536743, 5.5, 5.49300003051758, 5.47200012207031, 5.42999982833862, 5.39499998092651, 5.33599996566772, 5.32399988174438, 5.31099987030029, 5.29300022125244, 5.27899980545044, 5.27299976348877, 5.26900005340576, 5.26200008392334, 5.25, 5.23699998855591, 5.2350001335144, 5.23400020599365, 5.23000001907349, 5.22700023651123, 5.22499990463257, 5.19500017166138, 5.18200016021729, 5.18100023269653, 5.17500019073486, 5.15100002288818, 5.07399988174438, 5.07399988174438, 5.04099988937378, 5.01100015640259, 5.00400018692017, 4.96199989318848, 4.95499992370605, 4.8289999961853, 4.80499982833862, 4.77500009536743, 4.7350001335144, 4.71400022506714, 4.70900011062622, 4.69500017166138, 4.69199991226196, 4.64400005340576, 4.60799980163574, 4.57399988174438, 4.55299997329712, 4.55000019073486, 4.54500007629395, 4.53499984741211, 4.51399993896484, 4.49700021743774, 4.46500015258789, 4.46000003814697, 4.44000005722046, 4.37599992752075, 4.31500005722046, 4.29199981689453, 4.29099988937378, 4.28599977493286, 4.28000020980835, 4.19000005722046, 4.17999982833862, 4.16800022125244, 4.13899993896484, 4.11999988555908, 4.09600019454956, 4.08099985122681, 4.03200006484985, 4.02799987792969, 3.97000002861023, 3.93600010871887, 3.875, 3.80800008773804, 3.79500007629395, 3.79399991035461, 3.76600003242493, 3.65700006484985, 3.64400005340576, 3.6029999256134, 3.59299993515015, 3.59100008010864, 3.53299999237061, 3.50699996948242, 3.49499988555908, 3.47099995613098, 3.46199989318848, 3.34899997711182, 2.90499997138977, 2.69300007820129]\n",
      "[1.61646318435669, 1.48238301277161, 1.480633020401, 1.56497955322266, 1.44357192516327, 1.50394463539124, 1.47920441627502, 1.40570604801178, 1.49438726902008, 1.484414935112, 1.37538242340088, 1.10970628261566, 1.48709726333618, 1.54625928401947, 1.53570663928986, 1.48792338371277, 1.46378076076508, 1.74194359779358, 1.44163393974304, 1.25278460979462, 1.62634336948395, 1.10735321044922, 1.35268235206604, 1.18529546260834, 1.15318381786346, 1.69227766990662, 1.34327983856201, 1.21755969524384, 0.872001945972443, 1.23374843597412, 1.43092346191406, 1.12786877155304, 1.43362653255463, 1.38439786434174, 1.87076568603516, 1.07062232494354, 1.53062355518341, 1.36135590076447, 1.63295245170593, 1.32539355754852, 1.48841226100922, 1.29121541976929, 0.737299203872681, 1.00082039833069, 0.909784495830536, 1.29178786277771, 0.786441087722778, 1.39506661891937, 1.28177809715271, 0.907975316047668, 1.41691517829895, 1.31458234786987, 1.09186446666718, 1.26074862480164, 1.40167844295502, 0.728870630264282, 1.21768391132355, 0.833756566047668, 1.13077676296234, 1.28455626964569, 1.3469113111496, 1.3412059545517, 1.03522527217865, 1.18939554691315, 1.35593807697296, 1.32087934017181, 1.15655755996704, 1.10180306434631, 1.19827437400818, 0.932537317276001, 1.55167484283447, 0.85769921541214, 1.06931757926941, 0.991012394428253, 1.2860119342804, 0.925579309463501, 1.22255623340607, 0.951484382152557, 1.08116579055786, 0.72688353061676, 0.995538592338562, 1.12843120098114, 1.12112903594971, 0.878114581108093, 1.15360176563263, 1.07937383651733, 1.28948748111725, 1.07498753070831, 1.3151752948761, 0.982409417629242, 0.730573117733002, 1.06457793712616, 0.0226431842893362, 0.788547575473785, 0.783756256103516, 0.524713635444641, 0.885416388511658, 0.596220076084137, 0.479820191860199, 1.02723586559296, 1.05469870567322, 1.00726580619812, 0.716249227523804, 0.989701807498932, 1.1614590883255, 0.36842092871666, 0.564305365085602, 1.15687310695648, 0.996192753314972, 0.586682975292206, 0.964434325695038, 0.560479462146759, 0.234305649995804, 0.367110550403595, 0.479309022426605, 0.636406779289246, 1.10271048545837, 1.1982102394104, 0.339233845472336, 1.00985014438629, 0.900596737861633, 0.792221248149872, 0.648457288742065, 0.808964252471924, 0.950612664222717, 0.0921023488044739, 0.476180493831635, 0.603048920631409, 0.601765096187592, 0.65951669216156, 0.667224824428558, 0.89465194940567, 0.381430715322495, 0.3502277135849, 0.161925330758095, 0.233442038297653, 0.438012987375259, 0.375846534967422, 0.521021246910095, 0.858428180217743, 0.401477217674255, 1.12209415435791, 0.431085407733917, 0.305808693170547, 0.368610262870789, 0.591683447360992, 0.39724862575531, 0.119041793048382, 0.244549930095673, 0.305444717407227, 0.368745893239975, 0.777153134346008, 0.511135876178741, 0.091622568666935, 0.0]\n",
      "[0.635422587394714, 0.626006722450256, 0.627162635326385, 0.620070576667786, 0.617950856685638, 0.585384488105774, 0.611100912094116, 0.614062130451202, 0.612924098968506, 0.601607382297516, 0.405988603830338, 0.580131649971008, 0.567766189575195, 0.505740523338318, 0.573110342025757, 0.562511384487152, 0.539770722389221, 0.59662789106369, 0.508190035820007, 0.376895278692245, 0.60834527015686, 0.437453746795654, 0.490946173667908, 0.494519203901291, 0.412730008363724, 0.549840569496155, 0.588767051696777, 0.57939225435257, 0.531310617923737, 0.550026834011078, 0.470222115516663, 0.580200731754303, 0.361466586589813, 0.408781230449677, 0.604130983352661, 0.477487415075302, 0.449750572443008, 0.518630743026733, 0.496337592601776, 0.295817464590073, 0.536746919155121, 0.402264982461929, 0.447551846504211, 0.4551981985569, 0.432452529668808, 0.520342111587524, 0.658248662948608, 0.256450712680817, 0.373783111572266, 0.547509372234344, 0.505625545978546, 0.234231784939766, 0.233335807919502, 0.325707912445068, 0.257921665906906, 0.240729048848152, 0.457003742456436, 0.558732926845551, 0.41827192902565, 0.437454283237457, 0.471203625202179, 0.572575807571411, 0.450002878904343, 0.491247326135635, 0.355111539363861, 0.479131430387497, 0.295400261878967, 0.465733230113983, 0.300740599632263, 0.473507791757584, 0.490968644618988, 0.585214674472809, 0.208715528249741, 0.418421149253845, 0.175863519310951, 0.474307239055634, 0.255772292613983, 0.260287940502167, 0.472787708044052, 0.23521526157856, 0.443323463201523, 0.153997123241425, 0.194989055395126, 0.408158332109451, 0.398155838251114, 0.55258983373642, 0.0957312509417534, 0.288515985012054, 0.498465299606323, 0.204403176903725, 0.348079860210419, 0.325905978679657, 0.602126955986023, 0.571055591106415, 0.394952565431595, 0.471566706895828, 0.501537680625916, 0.454943388700485, 0.440305948257446, 0.394143968820572, 0.479246735572815, 0.289680689573288, 0.25471106171608, 0.282110154628754, 0.289231717586517, 0.318697690963745, 0.430388748645782, 0.249322608113289, 0.381498634815216, 0.478356659412384, 0.520303547382355, 0.452763766050339, 0.480791091918945, 0.514492034912109, 0.377922266721725, 0.461603492498398, 0.288555532693863, 0.312328577041626, 0.408842742443085, 0.561213254928589, 0.198303267359734, 0.469987004995346, 0.0960980430245399, 0.435025870800018, 0.309410035610199, 0.235961347818375, 0.306613743305206, 0.447706192731857, 0.633375823497772, 0.0149958552792668, 0.423026293516159, 0.122974775731564, 0.443185955286026, 0.324367851018906, 0.36365869641304, 0.466914653778076, 0.16234202682972, 0.336384207010269, 0.390661299228668, 0.0, 0.106179520487785, 0.505196332931519, 0.425962775945663, 0.189196765422821, 0.0303698573261499, 0.249463722109795, 0.147062435746193, 0.332881182432175, 0.348587512969971, 0.38042613863945, 0.581843852996826, 0.0815394446253777, 0.390017777681351, 0.0599007532000542, 0.270842045545578]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "f=open(\"data.csv\",\"r\")\n",
    "data=csv.DictReader(f)\n",
    "happScore=[]\n",
    "capital=[]\n",
    "freedom=[]\n",
    "for dataset in data:\n",
    "    happScore.append(float(dataset['Happiness.Score']))\n",
    "    capital.append(float(dataset['Economy..GDP.per.Capita.']))\n",
    "    freedom.append(float(dataset['Freedom']))\n",
    "print(happScore)\n",
    "print(capital)\n",
    "print(freedom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> split data Into train and test sets<br>\n",
    "> `train`: will have data for train the ML<br>\n",
    "> `test`: just for testing the ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for train: 120\n",
      "Data for test: 35\n"
     ]
    }
   ],
   "source": [
    "trainHappy=happScore[:120]\n",
    "trainCapital=capital[:120]\n",
    "trainFreedom=freedom[:120]\n",
    "#############################\n",
    "testHappy=happScore[120:]\n",
    "testCapital=capital[120:]\n",
    "testFreedom=freedom[120:]\n",
    "\n",
    "print(\"Data for train: \"+len(trainHappy).__str__())\n",
    "print(\"Data for test: \"+len(testHappy).__str__())\n",
    "\n",
    "# for i in range(len(trainHappy)):\n",
    "#     trainHappy[i]=1/trainHappy[i]\n",
    "# for i in range(len(trainCapital)):\n",
    "#     trainCapital[i]=1/trainCapital[i]\n",
    "# for i in range(len(trainFreedom)):\n",
    "#     trainFreedom[i]=1/trainFreedom[i]\n",
    "\n",
    "\n",
    "#[01]scale\n",
    "trainHappyScaled = [(p - min(trainHappy)) / (max(trainHappy) - min(trainHappy)) for p in trainHappy]\n",
    "trainCapitalScaled = [(p - min(trainCapital)) / (max(trainCapital) - min(trainCapital)) for p in trainCapital]\n",
    "trainFreedomScaled = [(p - min(trainFreedom)) / (max(testFreedom) - min(trainFreedom)) for p in trainFreedom]\n",
    "\n",
    "trainHappy=trainHappyScaled\n",
    "trainCapital=trainCapitalScaled\n",
    "trainFreedom=trainFreedomScaled\n",
    "\n",
    "\n",
    "\n",
    "#ZN\n",
    "# m=sum(trainHappy)/len(trainHappy)\n",
    "# s=(1/len(trainHappy)*sum([(p-m)**2 for p in trainHappy]))** 0.5\n",
    "# trainHappyZ=[(p-m)/s for p in trainHappy]\n",
    "#\n",
    "# m=sum(trainCapital)/len(trainCapital)\n",
    "# s=(1/len(trainCapital)*sum([(p-m)**2 for p in trainCapital]))** 0.5\n",
    "# trainCapitalZ=[(p-m)/s for p in trainCapital]\n",
    "#\n",
    "# m=sum(trainFreedom)/len(trainFreedom)\n",
    "# s=(1/len(trainFreedom)*sum([(p-m)**2 for p in trainFreedom]))** 0.5\n",
    "# trainFreedomZ=[(p-m)/s for p in trainFreedom]\n",
    "#\n",
    "#\n",
    "# trainHappy=trainHappyZ\n",
    "# trainCapital=trainCapitalZ\n",
    "# trainFreedom=trainFreedomZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I'll need the vector of coefficients, `w = []` where <br>\n",
    "&nbsp;&nbsp; w\\[0\\] will be `w0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init state of w=[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from myUtils import initCoef\n",
    "\n",
    "w=initCoef(2)\n",
    "print(\"Init state of w=\"+w.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Batch\n",
    "=-\n",
    "> calculate error after one full iteration over tests<br>\n",
    "> ...do that for a nr. of \"epochs\" / while error > smth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch: 0 error is: -0.43792914444403397\n",
      "At epoch: 1 error is: -0.39912044732242524\n",
      "At epoch: 2 error is: -0.36375092521664837\n",
      "At epoch: 3 error is: -0.33151580302043226\n",
      "At epoch: 4 error is: -0.30213731439122604\n",
      "At epoch: 5 error is: -0.27536230826955893\n",
      "At epoch: 6 error is: -0.2509600675054572\n",
      "At epoch: 7 error is: -0.22872032079528495\n",
      "At epoch: 8 error is: -0.20845143079809095\n",
      "At epoch: 9 error is: -0.18997874281867075\n",
      "At epoch: 10 error is: -0.17314307982813384\n",
      "At epoch: 11 error is: -0.1577993708537445\n",
      "At epoch: 12 error is: -0.14381540091902342\n",
      "At epoch: 13 error is: -0.13107067176249584\n",
      "At epoch: 14 error is: -0.1194553635180212\n",
      "At epoch: 15 error is: -0.1088693884096323\n",
      "At epoch: 16 error is: -0.09922152830667401\n"
     ]
    }
   ],
   "source": [
    "from myUtils import computeThis,initCoef\n",
    "error=10\n",
    "w=initCoef(2)\n",
    "learningRate=0.05\n",
    "Epoch=0\n",
    "while abs(error)>0.1:\n",
    "    error=computeThis(w,trainHappy,trainCapital,trainFreedom)\n",
    "    print(\"At epoch: \"+Epoch.__str__()+\" error is: \"+error.__str__())\n",
    "    w[0]=w[0]-learningRate*error\n",
    "    w[1]=w[1]-error*(sum(trainCapital)/len(trainCapital))*learningRate\n",
    "    w[2]=w[2]-error*(sum(trainFreedom)/len(trainFreedom))*learningRate\n",
    "    Epoch+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ERROR for multi-variate\n",
    "=-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0,W1,W2 set with an error of: 0.09922152830667401\n",
      "[0.1960650654089777, 0.11710677421038089, 0.12640095326546016]\n",
      "TEST:\n",
      "0.413230335977362\n",
      "0.9951564924987081\n"
     ]
    }
   ],
   "source": [
    "print(\"W0,W1,W2 set with an error of: \"+abs(error).__str__())\n",
    "print(w)\n",
    "print(\"TEST:\")\n",
    "print(w[0]+w[1]*trainCapital[1]+w[2]*trainFreedom[1])\n",
    "print(trainHappy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch: 0 error is: -0.43792914444403397\n",
      "At epoch: 1 error is: -0.4082211329895039\n",
      "At epoch: 2 error is: -0.38052843829518335\n",
      "At epoch: 3 error is: -0.35471434634202154\n",
      "At epoch: 4 error is: -0.3306514174460853\n",
      "At epoch: 5 error is: -0.30822085711099845\n",
      "At epoch: 6 error is: -0.287311929560165\n",
      "At epoch: 7 error is: -0.2678214110534953\n",
      "At epoch: 8 error is: -0.24965308028974442\n",
      "At epoch: 9 error is: -0.23271724337867922\n",
      "At epoch: 10 error is: -0.2169302910379358\n",
      "At epoch: 11 error is: -0.20221428582852893\n",
      "At epoch: 12 error is: -0.18849657739126505\n",
      "At epoch: 13 error is: -0.17570944378455203\n",
      "At epoch: 14 error is: -0.16378975715294516\n",
      "At epoch: 15 error is: -0.15267867207590197\n",
      "At epoch: 16 error is: -0.14232133505817104\n",
      "At epoch: 17 error is: -0.13266661372762376\n",
      "At epoch: 18 error is: -0.1236668444036214\n",
      "At epoch: 19 error is: -0.11527759678971237\n",
      "At epoch: 20 error is: -0.10745745462898175\n",
      "At epoch: 21 error is: -0.10016781123919266\n",
      "At epoch: 22 error is: -0.09337267891830778\n"
     ]
    }
   ],
   "source": [
    "import myUtils\n",
    "w=initCoef(1)\n",
    "learningRate=0.05\n",
    "Epoch=0\n",
    "error=10\n",
    "while abs(error)>0.1:\n",
    "    error=myUtils.cumputeUnivar(w,trainHappy,trainCapital)\n",
    "    print(\"At epoch: \"+Epoch.__str__()+\" error is: \"+error.__str__())\n",
    "    w[0]=w[0]-learningRate*error\n",
    "    w[1]=w[1]-error*learningRate*(sum(trainCapital)/len(trainCapital))\n",
    "    Epoch+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ERROR for `univariate`\n",
    "=-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09337267891830778\n",
      "[0.2586259181473325, 0.15447344960845474]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-a340d81c7e6d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSGDRegressor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mregressor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mSGDRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "print(abs(error))\n",
    "print(w)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "regressor=SGDRegressor()\n",
    "for i in range(20):\n",
    "    regressor.partial_fit(trainCapital,trainHappy)\n",
    "print(regressor.intercept_)\n",
    "print(regressor.coef_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}